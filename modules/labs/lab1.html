<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Lab 1 for Advanced Deep Learning Systems (ADLS) &mdash; MASE 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=92fd9be5" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=d45e8c67"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Lab 2 for Advanced Deep Learning Systems (ADLS)" href="lab2.html" />
    <link rel="prev" title="Advanced Deep Learning Systems Labs" href="../labs.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            MASE
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../documentation/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/specifications.html">Coding Style Specifications</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Machop API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/actions.html">Chop Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/passes.html">Chop Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/ir.html">IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mase Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../hardware/hardware_documentation.html">Hardware Documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Students</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../labs.html">Advanced Deep Learning Systems Labs</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Lab 1 for Advanced Deep Learning Systems (ADLS)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#general-introduction">General introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparation-and-installations">Preparation and installations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#getting-familiar-with-the-machop-command-line">Getting familiar with the Machop Command Line</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-your-first-network">Training your first network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-train-command">The train command</a></li>
<li class="toctree-l4"><a class="reference internal" href="#logging-on-tensorboard">Logging on tensorboard</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-test-command">The test command</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-definition-of-the-jsc-dataset">The definition of the JSC dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-definition-of-the-jsc-tiny-network">The definition of the JSC Tiny network</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#varying-the-parameters">Varying the parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#a-deeper-dive-into-the-framework">A deeper dive into the framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-entry-point-for-the-train-reset-action">The entry point for the train/reset action</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-entry-point-for-the-model">The entry point for the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-entry-point-for-the-dataset">The entry point for the dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#train-your-own-network">Train your own network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#google-colab-adaption">Google Colab Adaption</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lab2.html">Lab 2 for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab3.html">Lab 3 for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab4-hardware.html">Lab 4 (Hardware Stream) for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab4-software.html">Lab 4 (Software Stream) for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="setup_docker_env.html">ADLS Docker Environment Setup</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MASE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../labs.html">Advanced Deep Learning Systems Labs</a></li>
      <li class="breadcrumb-item active">Lab 1 for Advanced Deep Learning Systems (ADLS)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/modules/labs/lab1.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <a class="reference internal image-reference" href="../../_images/deepwok.png"><img alt="logo" class="align-center" src="../../_images/deepwok.png" style="width: 160.0px; height: 160.0px;" /></a>
<section id="lab-1-for-advanced-deep-learning-systems-adls">
<h1>Lab 1 for Advanced Deep Learning Systems (ADLS)<a class="headerlink" href="#lab-1-for-advanced-deep-learning-systems-adls" title="Link to this heading"></a></h1>
<div align="center">
<p align="center">
   ELEC70109/EE9-AML3-10/EE9-AO25
   <br />
Written by
   <a href="https://aaron-zhao123.github.io/">Aaron Zhao </a> ,
   <a href="https://chengzhang-98.github.io/blog/">Cheng Zhang </a> ,
   <a href="https://www.pedrogimenes.co.uk/">Pedro Gimenes </a>
</p>
</div><section id="general-introduction">
<h2>General introduction<a class="headerlink" href="#general-introduction" title="Link to this heading"></a></h2>
<p>In this lab, you will learn how to use the basic functionalities of the
software stack of MASE. There are in total 5 tasks you would need to finish.</p>
</section>
<section id="preparation-and-installations">
<h2>Preparation and installations<a class="headerlink" href="#preparation-and-installations" title="Link to this heading"></a></h2>
<p>Make sure you have read and understood the installation of the framework, detailed <a class="reference external" href="https://deepwok.github.io/mase/modules/documentation/getting_started/Get-started-on-local-machines-software-only.html">here</a>.</p>
<p>Both streams (software and hardware) would start from software first. We
are starting with simple toy networks that can train on most laptops.</p>
<p>The recommendation is to fork this repository to your own Github
account. If you are not familiar with <code class="docutils literal notranslate"><span class="pre">git</span></code>, <code class="docutils literal notranslate"><span class="pre">github</span></code> and
terminologies like <code class="docutils literal notranslate"><span class="pre">fork</span></code>. You might find this
<a class="reference external" href="https://docs.github.com/en/get-started/quickstart/fork-a-repo">webpage</a>
useful. You might also want to work on your own
<a class="reference external" href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-branches">branch</a>.</p>
<p>Please be aware that pushing to the <code class="docutils literal notranslate"><span class="pre">main</span></code> branch would be blocked,
and your final project would be submitted as a <a class="reference external" href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests">pull
request</a>.</p>
</section>
<section id="getting-familiar-with-the-machop-command-line">
<h2>Getting familiar with the Machop Command Line<a class="headerlink" href="#getting-familiar-with-the-machop-command-line" title="Link to this heading"></a></h2>
<p>The software framework of MASE is called Machop, you can find a reason
for the naming in the Machop <a class="reference external" href="https://github.com/DeepWok/mase/tree/main/machop">Readme</a>.</p>
<p>After installation, you should be able to run</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./ch<span class="w"> </span>--help
</pre></div>
</div>
<p>You should see a print out of a list of options and a usage guide, this
is also a good test for your installation. If your installation is
incorrect, this command will throw you an error.</p>
<p>The print out has the following lines:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>main<span class="w"> </span>arguments:
<span class="w">  </span>action<span class="w">                </span>action<span class="w"> </span>to<span class="w"> </span>perform.<span class="w"> </span>One<span class="w"> </span>of<span class="w"> </span><span class="o">(</span>train<span class="p">|</span>test<span class="p">|</span>transform<span class="p">|</span>search<span class="o">)</span>
<span class="w">  </span>model<span class="w">                 </span>name<span class="w"> </span>of<span class="w"> </span>a<span class="w"> </span>supported<span class="w"> </span>model.<span class="w"> </span>Required<span class="w"> </span><span class="k">if</span><span class="w"> </span>configuration<span class="w"> </span>NOT<span class="w"> </span>provided.
<span class="w">  </span>dataset<span class="w">               </span>name<span class="w"> </span>of<span class="w"> </span>a<span class="w"> </span>supported<span class="w"> </span>dataset.<span class="w"> </span>Required<span class="w"> </span><span class="k">if</span><span class="w"> </span>configuration<span class="w"> </span>NOT<span class="w"> </span>provided.
</pre></div>
</div>
<p>This means the <code class="docutils literal notranslate"><span class="pre">ch</span></code> command line tool expects three compulsory inputs
that are <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">model</span></code> and <code class="docutils literal notranslate"><span class="pre">dataset</span></code> respectively. These three
components would have to be either defined in the command line interface
or be defined in a configuration file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># example</span>
<span class="c1"># train is an action, mnist is the dataset and toynet is the model name.</span>
<span class="c1"># you do not have to run the command for now.</span>
./ch<span class="w"> </span>train<span class="w"> </span>toy<span class="w"> </span>mnist
</pre></div>
</div>
<p>The command line interface also allows you to input additional arguments
to control the training and testing flow.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># example</span>
<span class="c1"># setting the maximum training epochs and batch size through the cmd line interface.</span>
<span class="c1"># you do not have to run the command for now.</span>
./ch<span class="w"> </span>train<span class="w"> </span>toy<span class="w"> </span>mnist<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">200</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">256</span>
</pre></div>
</div>
</section>
<section id="training-your-first-network">
<h2>Training your first network<a class="headerlink" href="#training-your-first-network" title="Link to this heading"></a></h2>
<p>In this section, we are interested in training a small network and
evaluate the trained network through the command line flow.</p>
<p>The dataset we look at is the Jet Substructure Classification (JSC)
dataset.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>[A bit of physics] Jets are collimated showers of particles that
result from the decay and hadronization of quarks q and gluons g. At
the Large Hadron Collider (LHC), due to the high collision energy, a
particularly interesting jet signature emerges from overlapping
quark-initiated showers produced in decays of heavy standard model
particles. It is the task of jet substructure to distinguish the
various radiation profiles of these jets from backgrounds consisting
mainly of quark (u, d, c, s, b) and gluon-initiated jets. The tools
of jet substructure have been used to distinguish interesting jet
signatures from backgrounds that have production rates hundreds of
times larger than the signal.</p>
</div>
<p>In short, the dataset contains inputs with a feature size of 16 and 5
output classes.</p>
<section id="the-train-command">
<h3>The train command<a class="headerlink" href="#the-train-command" title="Link to this heading"></a></h3>
<p>To train a network for the JSC dataset, you would need to run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># You will need to run this command</span>
./ch<span class="w"> </span>train<span class="w"> </span>jsc-tiny<span class="w"> </span>jsc<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">256</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">--max-epochs</span></code> states the maximum epochs allowed to train, and
<code class="docutils literal notranslate"><span class="pre">--batch-size</span></code> defines the batch size for training.</p>
<p>You should see a print out of the training configuration in a table</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>+-------------------------+--------------------------+-----------------+--------------------------+
<span class="p">|</span><span class="w"> </span>Name<span class="w">                    </span><span class="p">|</span><span class="w">         </span>Default<span class="w">          </span><span class="p">|</span><span class="w"> </span>Manual<span class="w"> </span>Override<span class="w"> </span><span class="p">|</span><span class="w">        </span>Effective<span class="w">         </span><span class="p">|</span>
+-------------------------+--------------------------+-----------------+--------------------------+
<span class="p">|</span><span class="w"> </span>task<span class="w">                    </span><span class="p">|</span><span class="w">      </span>classification<span class="w">      </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">      </span>classification<span class="w">      </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>load_name<span class="w">               </span><span class="p">|</span><span class="w">           </span>None<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span>None<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>load_type<span class="w">               </span><span class="p">|</span><span class="w">            </span>mz<span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span>mz<span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>batch_size<span class="w">              </span><span class="p">|</span><span class="w">           </span><span class="m">128</span><span class="w">            </span><span class="p">|</span><span class="w">       </span><span class="m">256</span><span class="w">       </span><span class="p">|</span><span class="w">           </span><span class="m">256</span><span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>to_debug<span class="w">                </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>log_level<span class="w">               </span><span class="p">|</span><span class="w">           </span>info<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span>info<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>seed<span class="w">                    </span><span class="p">|</span><span class="w">            </span><span class="m">0</span><span class="w">             </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">0</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>training_optimizer<span class="w">      </span><span class="p">|</span><span class="w">           </span>adam<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span>adam<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>trainer_precision<span class="w">       </span><span class="p">|</span><span class="w">            </span><span class="m">32</span><span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">32</span><span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>learning_rate<span class="w">           </span><span class="p">|</span><span class="w">          </span>1e-05<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">          </span>1e-05<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>weight_decay<span class="w">            </span><span class="p">|</span><span class="w">            </span><span class="m">0</span><span class="w">             </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">0</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>max_epochs<span class="w">              </span><span class="p">|</span><span class="w">            </span><span class="m">20</span><span class="w">            </span><span class="p">|</span><span class="w">       </span><span class="m">10</span><span class="w">        </span><span class="p">|</span><span class="w">            </span><span class="m">10</span><span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>max_steps<span class="w">               </span><span class="p">|</span><span class="w">            </span>-1<span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span>-1<span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>accumulate_grad_batches<span class="w"> </span><span class="p">|</span><span class="w">            </span><span class="m">1</span><span class="w">             </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">1</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>log_every_n_steps<span class="w">       </span><span class="p">|</span><span class="w">            </span><span class="m">50</span><span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">50</span><span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>num_workers<span class="w">             </span><span class="p">|</span><span class="w">            </span><span class="m">16</span><span class="w">            </span><span class="p">|</span><span class="w">        </span><span class="m">0</span><span class="w">        </span><span class="p">|</span><span class="w">            </span><span class="m">0</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>num_devices<span class="w">             </span><span class="p">|</span><span class="w">            </span><span class="m">1</span><span class="w">             </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">1</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>num_nodes<span class="w">               </span><span class="p">|</span><span class="w">            </span><span class="m">1</span><span class="w">             </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">            </span><span class="m">1</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>accelerator<span class="w">             </span><span class="p">|</span><span class="w">           </span>auto<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span>auto<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>strategy<span class="w">                </span><span class="p">|</span><span class="w">           </span>ddp<span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span>ddp<span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>is_to_auto_requeue<span class="w">      </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>github_ci<span class="w">               </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>disable_dataset_cache<span class="w">   </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>target<span class="w">                  </span><span class="p">|</span><span class="w">   </span>xcu250-figd2104-2L-e<span class="w">   </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">   </span>xcu250-figd2104-2L-e<span class="w">   </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>num_targets<span class="w">             </span><span class="p">|</span><span class="w">           </span><span class="m">100</span><span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span><span class="m">100</span><span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>is_pretrained<span class="w">           </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">          </span>False<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>max_token_len<span class="w">           </span><span class="p">|</span><span class="w">           </span><span class="m">512</span><span class="w">            </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span><span class="m">512</span><span class="w">            </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>project_dir<span class="w">             </span><span class="p">|</span><span class="w"> </span>/Users/aaron/Projects/ma<span class="w"> </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w"> </span>/Users/aaron/Projects/ma<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">                         </span><span class="p">|</span><span class="w">   </span>se-tools/mase_output<span class="w">   </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">   </span>se-tools/mase_output<span class="w">   </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>project<span class="w">                 </span><span class="p">|</span><span class="w">           </span>None<span class="w">           </span><span class="p">|</span><span class="w">                 </span><span class="p">|</span><span class="w">           </span>None<span class="w">           </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>model<span class="w">                   </span><span class="p">|</span><span class="w">           </span>None<span class="w">           </span><span class="p">|</span><span class="w">    </span>jsc-tiny<span class="w">     </span><span class="p">|</span><span class="w">         </span>jsc-tiny<span class="w">         </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>dataset<span class="w">                 </span><span class="p">|</span><span class="w">           </span>None<span class="w">           </span><span class="p">|</span><span class="w">       </span>jsc<span class="w">       </span><span class="p">|</span><span class="w">           </span>jsc<span class="w">            </span><span class="p">|</span>
+-------------------------+--------------------------+-----------------+--------------------------+
</pre></div>
</div>
<p>There is also a summary on the model</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="p">|</span><span class="w"> </span>Name<span class="w">      </span><span class="p">|</span><span class="w"> </span>Type<span class="w">               </span><span class="p">|</span><span class="w"> </span>Params
-------------------------------------------------
<span class="m">0</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>model<span class="w">     </span><span class="p">|</span><span class="w"> </span>JSC_Tiny<span class="w">           </span><span class="p">|</span><span class="w"> </span><span class="m">127</span>
<span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>loss_fn<span class="w">   </span><span class="p">|</span><span class="w"> </span>CrossEntropyLoss<span class="w">   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>
<span class="m">2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>acc_train<span class="w"> </span><span class="p">|</span><span class="w"> </span>MulticlassAccuracy<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>
<span class="m">3</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>acc_val<span class="w">   </span><span class="p">|</span><span class="w"> </span>MulticlassAccuracy<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>
<span class="m">4</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>acc_test<span class="w">  </span><span class="p">|</span><span class="w"> </span>MulticlassAccuracy<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>
<span class="m">5</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>loss_val<span class="w">  </span><span class="p">|</span><span class="w"> </span>MeanMetric<span class="w">         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>
<span class="m">6</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>loss_test<span class="w"> </span><span class="p">|</span><span class="w"> </span>MeanMetric<span class="w">         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>
-------------------------------------------------
<span class="m">127</span><span class="w">       </span>Trainable<span class="w"> </span>params
<span class="m">0</span><span class="w">         </span>Non-trainable<span class="w"> </span>params
<span class="m">127</span><span class="w">       </span>Total<span class="w"> </span>params
<span class="m">0</span>.001<span class="w">     </span>Total<span class="w"> </span>estimated<span class="w"> </span>model<span class="w"> </span>params<span class="w"> </span>size<span class="w"> </span><span class="o">(</span>MB<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="logging-on-tensorboard">
<h3>Logging on tensorboard<a class="headerlink" href="#logging-on-tensorboard" title="Link to this heading"></a></h3>
<p>As you can see, this is a toy model and it is very small. There is
another print out line that is also very useful:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Project<span class="w"> </span>will<span class="w"> </span>be<span class="w"> </span>created<span class="w"> </span>at<span class="w"> </span>/home/cheng/GTA/adls/mase-tools/mase_output/jsc-tiny_classification_jsc_2023-10-30
Missing<span class="w"> </span>logger<span class="w"> </span>folder:<span class="w"> </span>/Users/aaron/Projects/mase-tools/mase_output/jsc-tiny_classification_jsc_2023-10-19/software/training_ckpts/logs
</pre></div>
</div>
<p>For any training commands executed, a logging directory would be created
and one can use <a class="reference external" href="https://www.tensorflow.org/tensorboard">tensorboard</a>
to check the training trajectory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># You need to run the following command with your own edits</span>

<span class="c1"># the actual name of the log file created for you would be different from the example showing here, because the name contains a time-stamp.</span>

<span class="c1"># --port 16006 is declaring the port on localhost</span>
tensorboard<span class="w"> </span>--logdir<span class="w"> </span>../mase_output/jsc-tiny_classification_jsc_2023-10-19/software<span class="w"> </span>--port<span class="w"> </span><span class="m">16006</span>
</pre></div>
</div>
<p>Open <code class="docutils literal notranslate"><span class="pre">http://localhost:16006/</span></code> in your preferred browser, explore on
the entries that have been logged.</p>
</section>
<section id="the-test-command">
<h3>The test command<a class="headerlink" href="#the-test-command" title="Link to this heading"></a></h3>
<p>Under the same folder
<code class="docutils literal notranslate"><span class="pre">../mase_output/jsc-tiny_classification_jsc_2023-10-19/software</span></code>,
there are also saved checkpoint files for the trained models. These are
basically the trained parameters of the model, one can find more detail
on Pytorch model checkpointing
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html">here</a>
and Lightning checkpointing
<a class="reference external" href="https://lightning.ai/docs/pytorch/stable/common/checkpointing.html">here</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./ch<span class="w"> </span><span class="nb">test</span><span class="w"> </span>jsc-tiny<span class="w"> </span>jsc<span class="w"> </span>--load<span class="w"> </span>../mase_output/jsc-tiny_classification_jsc_2023-10-19/software/training_ckpts/best.ckpt<span class="w"> </span>--load-type<span class="w"> </span>pl
</pre></div>
</div>
<p>The above command would return you the performance of the trained model
on the test set. <code class="docutils literal notranslate"><span class="pre">--load-type</span> <span class="pre">pl</span></code> tells Machop that the checkpoint is
saved by PyTorch Lightning. For PyTorch Lightning, see <a class="reference external" href="#the-entry-point-for-the-train-reset-action">this
section</a></p>
<p>The saved checkpoint can also be used to resume training.</p>
</section>
<section id="the-definition-of-the-jsc-dataset">
<h3>The definition of the JSC dataset<a class="headerlink" href="#the-definition-of-the-jsc-dataset" title="Link to this heading"></a></h3>
<p>Datasets are defined in under the
<a class="reference external" href="https://github.com/DeepWok/mase/tree/main/machop/chop/dataset">dataset</a> folder in <code class="docutils literal notranslate"><span class="pre">chop</span></code>, one should
take a look at the
<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/dataset/__init__.py">__init__.py</a> to understand
how different datasets are declared. The JSC dataset is defined and
detailed in <a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/dataset/physical/jsc.py">this
file</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@add_dataset_info</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;jsc&quot;</span><span class="p">,</span>
    <span class="n">dataset_source</span><span class="o">=</span><span class="s2">&quot;manual&quot;</span><span class="p">,</span>
    <span class="n">available_splits</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">),</span>
    <span class="n">physical_data_point_classification</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">num_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">class</span> <span class="nc">JetSubstructureDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_file</span><span class="p">,</span> <span class="n">config_file</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
  <span class="o">...</span>
</pre></div>
</div>
<p>The
<a class="reference external" href="https://book.pythontips.com/en/latest/decorators.html">decorator</a>
(if you do not know what is a python decorator, click the link and
learn) defines the dataset information required. The class object
<code class="docutils literal notranslate"><span class="pre">JetSubstructureDataset</span></code> has <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> being its parent class. If
you are still concerned with your proficiency in OOP (object orientated
programming), you should check this
<a class="reference external" href="https://book.pythontips.com/en/latest/classes.html">link</a>.</p>
</section>
<section id="the-definition-of-the-jsc-tiny-network">
<h3>The definition of the JSC Tiny network<a class="headerlink" href="#the-definition-of-the-jsc-tiny-network" title="Link to this heading"></a></h3>
<p>The network definition can also be found in the
<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/models/physical/jet_substructure/__init__.py">__init__.py</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">JSC_Tiny</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">JSC_Tiny</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># 1st LogicNets Layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>  <span class="c1">#  batch norm layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>  <span class="c1"># linear layer</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>Network definitions in Pytorch normally contains two components: an
<code class="docutils literal notranslate"><span class="pre">__init__</span></code> method and a <code class="docutils literal notranslate"><span class="pre">forward</span></code> method. Also all networks and
custom layers in Pytorch has to be a subclass of <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>. The
neural network layers are initialised in <code class="docutils literal notranslate"><span class="pre">__init__</span></code>. Every
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> subclass implements the operations on input data in the
<code class="docutils literal notranslate"><span class="pre">forward</span></code> method.</p>
<p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> is a container used for wrapping a number of layers
together, more information on this container can be found in this
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html">link</a>.</p>
</section>
</section>
<section id="varying-the-parameters">
<h2>Varying the parameters<a class="headerlink" href="#varying-the-parameters" title="Link to this heading"></a></h2>
<p>We have executed the following training command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./ch<span class="w"> </span>train<span class="w"> </span>jsc-tiny<span class="w"> </span>jsc<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">256</span>
</pre></div>
</div>
<p>We can, apparently, tune a bunch of parameters, and the obvious ones to
tune are</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">batch-size</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max-epochs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning-rate</span></code></p></li>
</ul>
<p>Tune these parameters by hand and answer the following questions:</p>
<ol class="arabic simple">
<li><p>What is the impact of varying batch sizes and why?</p></li>
<li><p>What is the impact of varying maximum epoch number?</p></li>
<li><p>What is happening with a large learning and what is happening with a
small learning rate and why? What is the relationship between
learning rates and batch sizes?</p></li>
</ol>
</section>
<section id="a-deeper-dive-into-the-framework">
<h2>A deeper dive into the framework<a class="headerlink" href="#a-deeper-dive-into-the-framework" title="Link to this heading"></a></h2>
<p>When you execute <code class="docutils literal notranslate"><span class="pre">./ch</span></code>, what really happens is the
<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/ch">ch</a> file got executed and from the <code class="docutils literal notranslate"><span class="pre">import</span></code> you
can tell it is calling into <a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/cli.py">cli.py</a>.</p>
<section id="the-entry-point-for-the-train-reset-action">
<h3>The entry point for the train/reset action<a class="headerlink" href="#the-entry-point-for-the-train-reset-action" title="Link to this heading"></a></h3>
<p>When you choose to execute <code class="docutils literal notranslate"><span class="pre">./ch</span> <span class="pre">train</span></code>, we are executing the train
action, and invoking <a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/actions/train.py">train.py</a>.
The entire training flow is orchestrated using <a class="reference external" href="https://lightning.ai/">PyTorch
Lightning</a>, so that the detailed lightning
related wrapping occurs in
<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/plt_wrapper/physical/jet_substructure.py">jet_substructure.py</a>.
PyTorch Lightning’s checkpointing callbacks saves the model parameters
(<code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>), the optimizer states, and other
hyper-parameters specified in <code class="docutils literal notranslate"><span class="pre">lightning.pl.LightningModule</span></code>, so that
the training can be resumed from the last checkpoint. The saved
checkpoint has extension <code class="docutils literal notranslate"><span class="pre">.ckpt</span></code>, this is why we have
<code class="docutils literal notranslate"><span class="pre">--load-type</span> <span class="pre">pl</span></code> in the <code class="docutils literal notranslate"><span class="pre">./ch</span> <span class="pre">test</span></code> command.</p>
<p>Test action has similar implementation based on PyTorch Lightning
(<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/actions/test.py">test.py</a>)</p>
</section>
<section id="the-entry-point-for-the-model">
<h3>The entry point for the model<a class="headerlink" href="#the-entry-point-for-the-model" title="Link to this heading"></a></h3>
<p>All models are defined in the
<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/models/__init__.py">__init__.py</a> under the model
folder. The <code class="docutils literal notranslate"><span class="pre">get_model</span></code> function is called inside <code class="docutils literal notranslate"><span class="pre">actions</span></code> (such as
<code class="docutils literal notranslate"><span class="pre">train</span></code>) to ping down different models.</p>
</section>
<section id="the-entry-point-for-the-dataset">
<h3>The entry point for the dataset<a class="headerlink" href="#the-entry-point-for-the-dataset" title="Link to this heading"></a></h3>
<p>Similar to the model definitions, all datasets are defined in the
<a class="reference external" href="https://github.com/DeepWok/mase/blob/main/machop/chop/dataset/__init__.py">__init__.py</a> under the
dataset folder.</p>
</section>
</section>
<section id="train-your-own-network">
<h2>Train your own network<a class="headerlink" href="#train-your-own-network" title="Link to this heading"></a></h2>
<p>Now you are familiar with different components in the tool.</p>
<ol class="arabic simple" start="4">
<li><p>Implement a network that has in total around 10x more parameters than
the toy network.</p></li>
<li><p>Test your implementation and evaluate its performance.</p></li>
</ol>
</section>
<section id="google-colab-adaption">
<h2>Google Colab Adaption<a class="headerlink" href="#google-colab-adaption" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://github.com/DeepWok/mase/blob/main/docs/labs/lab1.ipynb">lab1.ipynb</a> contains an adaption of setting up the
same thing on Google Colab. You would need to repeat the exercise on
that because you would definitely need a powerful GPU for later labs and
your Team Projects.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../labs.html" class="btn btn-neutral float-left" title="Advanced Deep Learning Systems Labs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lab2.html" class="btn btn-neutral float-right" title="Lab 2 for Advanced Deep Learning Systems (ADLS)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepWok.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>