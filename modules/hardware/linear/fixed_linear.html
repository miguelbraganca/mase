<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Fixed-Point Linear Layer &mdash; MASE 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=92fd9be5" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=d45e8c67"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Matrix Bank" href="../memory/matrix_bank.html" />
    <link rel="prev" title="Hybrid Buffer" href="../buffers/hybrid_buffer.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            MASE
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/specifications.html">Coding Style Specifications</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Machop API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/actions.html">Chop Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/passes.html">Chop Passes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/ir.html">IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mase Components</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../hardware_documentation.html">Hardware Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../arithmetic/mac.html">Multiply-Accumulate (MAC) Unit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../axi/read_master.html">AXI Read Master</a></li>
<li class="toctree-l2"><a class="reference internal" href="../buffers/hybrid_buffer.html">Hybrid Buffer</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Fixed-Point Linear Layer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-dataflow">Example dataflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#latency-analysis"><a name="latency_analaysis"></a> Latency Analysis</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../memory/matrix_bank.html">Matrix Bank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../systolic_modules/output_stationary.html">Output Stationary Systolic Module</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Students</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../labs.html">Advanced Deep Learning Systems Labs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MASE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../hardware_documentation.html">Hardware Documentation</a></li>
      <li class="breadcrumb-item active">Fixed-Point Linear Layer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/modules/hardware/linear/fixed_linear.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="fixed-point-linear-layer">
<h1>Fixed-Point Linear Layer<a class="headerlink" href="#fixed-point-linear-layer" title="Link to this heading"></a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">fixed_linear</span></code> module implements the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">Pytorch Linear</a> layer. Given the input vector <span class="math notranslate nohighlight">\(x \in \R^{m}\)</span>, weights matrix <span class="math notranslate nohighlight">\(W \in \R^{n \times m}\)</span>, and bias row vector <span class="math notranslate nohighlight">\(b \in R^n\)</span> where <span class="math notranslate nohighlight">\(m, n\)</span> are the input and output feature counts respectively, <code class="docutils literal notranslate"><span class="pre">fixed_linear</span></code> returns <span class="math notranslate nohighlight">\(y \in \R^{n}\)</span>. For example, taking <span class="math notranslate nohighlight">\(m = n = 4\)</span>:</p>
<p><span class="math notranslate nohighlight">\(y = x W^T + b = \)</span>
<span class="math notranslate nohighlight">\( \begin{bmatrix}
x_1 &amp; x_2 &amp; x_3 &amp; x_4
\end{bmatrix}  \)</span>
<span class="math notranslate nohighlight">\( \begin{bmatrix}
w_{1, 1} &amp; w_{1, 2} &amp; w_{1, 3} &amp; w_{1, 4} \\
w_{2, 1} &amp; w_{2, 2} &amp; w_{2, 3} &amp; w_{2, 4} \\
w_{3, 1} &amp; w_{3, 2} &amp; w_{3, 3} &amp; w_{3, 4} \\
w_{4, 1} &amp; w_{4, 2} &amp; w_{4, 3} &amp; w_{4, 4}
\end{bmatrix}  \)</span> +
<span class="math notranslate nohighlight">\( \begin{bmatrix}
b_1 &amp; b_2 &amp; b_3 &amp; b_4
\end{bmatrix}  \)</span> = <span class="math notranslate nohighlight">\( \begin{bmatrix}
y_1 &amp; y_2 &amp; y_3 &amp; y_4
\end{bmatrix}  \)</span></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">fixed_linear</span></code> module follows the dataflow streaming protocol and works through a sequential dot product operation.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/DeepWok/mase/main/machop/sphinx_docs/source/imgs/linear/fixed_linear.png" alt="img">
</p>
<p>The module has the following parameters, following the hardware metadata standard (see <a class="reference external" href="https://deepwok.github.io/mase/modules/api/analysis/add_metadata.html#add-hardware-metadata-analysis-pass">here</a>). Besides <code class="docutils literal notranslate"><span class="pre">PRECISION_DIM_*</span></code> parameters, which dictate the numerical precision, and <code class="docutils literal notranslate"><span class="pre">TENSOR_SIZE_DIM_*</span></code>, which is directly inferred from Pytorch tensor shapes, the following parameters can be adjusted to affect hardware performance.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>DATA_IN_0_PARALLELISM_DIM_0</p></td>
<td><p>4</p></td>
<td><p>Number of elements per transaction at the input interface. Dictates the number of transactions to compute the full layer.</p></td>
</tr>
<tr class="row-odd"><td><p>WEIGHT_PARALLELISM_DIM_0</p></td>
<td><p>4</p></td>
<td><p>Number of columns of the weights matrix per transaction at the weights interface. This is equivalent to the number of dot product modules. Also dictates the number of backpressure cycles on the input interface (see <a class="reference internal" href="#latency-analysis"><span class="xref myst">Latency Analysis</span></a> below)</p></td>
</tr>
<tr class="row-even"><td><p>DATA_OUT_0_PARALLELISM_DIM_0</p></td>
<td><p>WEIGHT_PARALLELISM_DIM_0</p></td>
<td><p>Number of elements per transaction at the output interface.</p></td>
</tr>
<tr class="row-odd"><td><p>BIAS_PARALLELISM_DIM_0</p></td>
<td><p>WEIGHT_PARALLELISM_DIM_0</p></td>
<td><p>Number of elements per transaction at the bias interface. Dictates the number of fixed-point adders.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example-dataflow">
<h2>Example dataflow<a class="headerlink" href="#example-dataflow" title="Link to this heading"></a></h2>
<p>Assume a configuration where DATA_&lt;IN/OUT&gt;_TENSOR_SIZE <span class="math notranslate nohighlight">\(= 4\)</span>, DATA_IN_PARALLELISM <span class="math notranslate nohighlight">\(= 2\)</span> and WEIGHT_PARALLELISM <span class="math notranslate nohighlight">\(= 2\)</span>. Hence each input data beat has a sub-vector of 2 elements, each weight beat has 4 elements (2 sub-columns of 2 elements) and there are 2 dot product modules. When the first data beat is driven valid, <code class="docutils literal notranslate"><span class="pre">fixed_linear</span></code> accepts the first weight beat and stalls back the input interface, while driving the dot product modules to compute <span class="math notranslate nohighlight">\(X_1 \cdot W_1\)</span> and <span class="math notranslate nohighlight">\(X_1 \cdot W_2\)</span>. This results in partial results for the output sub-vector <span class="math notranslate nohighlight">\(Y_1\)</span>.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/DeepWok/mase/main/machop/sphinx_docs/source/imgs/linear/matrix_multiply1.png" alt="img">
</p>
<p>The partial outputs are stored in local registers in the next cycle while <span class="math notranslate nohighlight">\(X_1 \cdot W_3\)</span> and <span class="math notranslate nohighlight">\(A \cdot W_4\)</span> are computed resulting in partial products for the output sub-vector <span class="math notranslate nohighlight">\(Y_2\)</span> and the ready signal is driven for the input data interface.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/DeepWok/mase/main/machop/sphinx_docs/source/imgs/linear/matrix_multiply2.png" alt="img">
</p>
<p>The same process is repeated with the second input sub-vector <span class="math notranslate nohighlight">\(X_2\)</span> and weight sub-columns <span class="math notranslate nohighlight">\(W_{5..8}\)</span>. The final output sub-vectors <span class="math notranslate nohighlight">\(Y_1\)</span> and <span class="math notranslate nohighlight">\(Y_2\)</span> are ready and streamed out after the 3rd and 4th cycles, respectively.</p>
<p align="center">
  <img src="https://raw.githubusercontent.com/DeepWok/mase/main/machop/sphinx_docs/source/imgs/linear/matrix_multiply3.png" alt="img">
</p>
</section>
<section id="latency-analysis">
<h2><a name="latency_analaysis"></a> Latency Analysis<a class="headerlink" href="#latency-analysis" title="Link to this heading"></a></h2>
<p>The time taken to compute a linear layer using the <code class="docutils literal notranslate"><span class="pre">fixed_linear</span></code> module, <span class="math notranslate nohighlight">\(L_{FL}\)</span> can be broken down into 2 phases, the input driving phase <span class="math notranslate nohighlight">\(L_L\)</span>, and the pipeline unloading phase <span class="math notranslate nohighlight">\(L_U\)</span> that begins after the last input beat is transferred.</p>
<p>When the WEIGHT_PARALLELISM_DIM_0 parameter is set to DATA_OUT_0_TENSOR_SIZE_0, the input tensor can be transferred at full bandwidth, hence <span class="math notranslate nohighlight">\(L_I\)</span> is equivalent to the number of cycles required to transfer the input tensor tensor size in DATA_IN_0_PARALLELISM_DIM_0 sized beats.</p>
<p><span class="math notranslate nohighlight">\(L_{FL} = L_I + L_U = \frac{\text{DATA_IN_0_TENSOR_SIZE}}{\text{DATA_IN_0_PARALLELISM}} + L_{DP} + L_{ACC}\)</span></p>
<p><span class="math notranslate nohighlight">\(L_U\)</span> is equivalent to the propagation latency of a given beat through the dot-product module <span class="math notranslate nohighlight">\(L_{DP}\)</span> and accumulator <span class="math notranslate nohighlight">\(L_{ACC}\)</span>, given by the following.</p>
<p><span class="math notranslate nohighlight">\(L_{DP} = 2 + log_2(\text{DATA_IN_0_PARALLELISM_DIM_0})\)</span></p>
<p><span class="math notranslate nohighlight">\(L_{ACC} = 1\)</span></p>
<p>When <span class="math notranslate nohighlight">\({\text{WEIGHT_PARALLELISM_DIM_0}} &lt; \text{DATA_OUT_0_TENSOR_SIZE\_0}\)</span>, the input driving bandwidth is reduced since a number of weight beats are read for each input beat. The input driving phase is scaled by the following factor, leading to the following total latency.</p>
<p><span class="math notranslate nohighlight">\(L_{FL} = \left(\frac{\text{DATA_IN_0_TENSOR_SIZE}}{\text{DATA_IN_0_PARALLELISM}}\right)\left(\frac{\text{WEIGHT_TENSOR_SIZE}}{\text{WEIGHT_PARALLELISM}}\right) + log_2(\text{DATA_IN_0_PARALLELISM_DIM_0}) + 3\)</span></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../buffers/hybrid_buffer.html" class="btn btn-neutral float-left" title="Hybrid Buffer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../memory/matrix_bank.html" class="btn btn-neutral float-right" title="Matrix Bank" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepWok.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>